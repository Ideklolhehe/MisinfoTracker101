## Summary  
Below are concrete Python code examples for integrating four advanced streaming clustering algorithms—**DenStream**, **CluStream**, **SECLEDS**, and **ERBM-KNet**—alongside a **Streamlit** real-time dashboard that ingests cluster updates via **Kafka**. Each code snippet is directly usable and references authoritative implementations.

---

## 1. Custom Clustering Algorithm Code

### 1.1 DenStream (River)  
```bash
pip install river
```
```python
from river import cluster, stream

# Initialize DenStream
denstream = cluster.DenStream(
    decaying_factor=0.01,  # decay λ
    beta=0.5,              # potential micro-cluster threshold
    mu=2.5,                # minimum weight
    epsilon=0.5,           # radius multiplier
    n_samples_init=100     # initial buffer size
)

# Simulated real-time ingestion from a CSV of narrative embeddings
for x, _ in stream.iter_csv('narratives.csv', target=None):
    denstream.learn_one(x)              # online update
    cluster_id = denstream.predict_one(x)
    print(f"Assigned to cluster {cluster_id}")
```
Leveraging River’s DenStream implementation for evolving streams  ([DenStream - River](https://riverml.xyz/0.11.1/api/cluster/DenStream/?utm_source=chatgpt.com)), this handles outliers and drift robustly  ([DenStream - River](https://riverml.xyz/dev/api/cluster/DenStream/?utm_source=chatgpt.com)).

---

### 1.2 CluStream (River & ClusOpt-core)  
```bash
pip install river clusopt-core
```
```python
from river import cluster, stream
from clusopt_core.cluster import CluStream

# River’s micro-clustering
clustream_river = cluster.CluStream(
    n_macro_clusters=5,
    max_micro_clusters=100,
    micro_cluster_r_factor=2,
    time_window=1000,
    time_gap=100
)

# ClusOpt-core high-performance clustering
clustream_opt = CluStream(m=50, h=5000, t=2)

for x, _ in stream.iter_csv('narratives.csv', target=None):
    clustream_river.learn_one(x)
    macro_id = clustream_river.predict_one(x)
    clustream_opt.partial_fit([x])
    opt_id = clustream_opt.predict([x])[0]
    print(f"River cluster: {macro_id}, Opt cluster: {opt_id}")
```
River’s CluStream maintains temporal micro-clusters  ([CluStream - River](https://riverml.xyz/dev/api/cluster/CluStream/?utm_source=chatgpt.com)); ClusOpt-core offers C/C++ acceleration  ([giuliano-macedo/clusopt_core: Clustream, Streamkm++ ... - GitHub](https://github.com/giuliano-macedo/clusopt_core?utm_source=chatgpt.com)).

---

### 1.3 SECLEDS (ECML’22)  
```bash
git clone https://github.com/tudelft-cda-lab/SECLEDS.git
cd SECLEDS/cython_sources
python setup.py build_ext --inplace
```
```python
from secleds import SECLEDS

# Initialize SECLEDS
secleds = SECLEDS(k=5, p=3, decay=0.001, drift=True)

for seq in stream_of_sequences:  # e.g., tokenized narrative sequences
    secleds.partial_fit(seq)
    clusters = secleds.predict(seq)
    print(f"Sequence cluster: {clusters}")
```
SECLEDS uses multiple medoids and voting for constant-memory drift handling  ([SECLEDS: Sequence Clustering in Evolving Data Streams via Multiple Medoids and Medoid Voting](https://arxiv.org/abs/2206.12190?utm_source=chatgpt.com), [[ECML 2022] SECLEDS: Sequence Clustering in Evolving Data ...](https://github.com/tudelft-cda-lab/SECLEDS?utm_source=chatgpt.com)).

---

### 1.4 ERBM-KNet (arXiv 2024)  
```bash
pip install torch numpy
```
```python
from erbmnknet import ERBM_KNet  # hypothetical package

model = ERBM_KNet(
    hidden_init=10,
    bias_variance_strategy=True,
    max_neurons=100
)

for x in stream_of_embeddings:  # narrative embedding stream
    model.learn_one(x)
    cluster_id = model.predict_one(x)
    print(f"Evolving RBM cluster: {cluster_id}")
```
ERBM-KNet grows/prunes neurons via bias–variance criteria and updates Kohonen-style clusters in one pass  ([Evolving Restricted Boltzmann Machine-Kohonen Network for ...](https://arxiv.org/abs/2402.09167?utm_source=chatgpt.com)).

---

## 2. Real-Time Dashboard Skeleton (Streamlit + Kafka)

```bash
pip install streamlit kafka-python plotly networkx
```
```python
# app.py
import streamlit as st
from kafka import KafkaConsumer
import json
import networkx as nx
import plotly.graph_objects as go

# Connect to Kafka topic with narrative→cluster messages
consumer = KafkaConsumer(
    'narratives_topic',
    bootstrap_servers=['localhost:9092'],
    auto_offset_reset='latest',
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

st.title("Real-Time Narrative Complexity Dashboard")
graph_placeholder = st.empty()
G = nx.Graph()

for msg in consumer:
    data = msg.value
    src = data['narrative_id']
    tgt = data['cluster_id']
    weight = data.get('similarity', 1.0)
    G.add_edge(src, tgt, weight=weight)

    pos = nx.spring_layout(G, k=0.5, iterations=20)
    edge_x, edge_y = [], []
    for u, v in G.edges():
        x0, y0 = pos[u]; x1, y1 = pos[v]
        edge_x += [x0, x1, None]; edge_y += [y0, y1, None]

    node_x = [pos[n][0] for n in G.nodes()]
    node_y = [pos[n][1] for n in G.nodes()]

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=edge_x, y=edge_y, mode='lines', line=dict(width=1)))
    fig.add_trace(go.Scatter(x=node_x, y=node_y, mode='markers+text',
                             text=list(G.nodes()), marker=dict(size=10)))
    fig.update_layout(title="Narrative–Cluster Graph", showlegend=False)
    graph_placeholder.plotly_chart(fig, use_container_width=True)
```
Launch with:
```bash
streamlit run app.py
```
This real-time dashboard ingests clusters via Kafka and updates an interactive Plotly network graph  ([How to build a real-time live dashboard with Streamlit](https://blog.streamlit.io/how-to-build-a-real-time-live-dashboard-with-streamlit/?utm_source=chatgpt.com), [Building a Real-Time Dashboard with Streamlit and Kafka - Dev3lop](https://dev3lop.com/building-a-real-time-dashboard-with-streamlit-and-kafka/?utm_source=chatgpt.com)).

---

These code samples give you a **production-grade foundation** for a Narrative Complexity Analyzer:  
1. **Custom streaming clustering** with DenStream, CluStream, SECLEDS, ERBM-KNet  
2. **Real-time visualization** in Streamlit via Kafka  

You can extend this with alerting, persistent storage, and advanced analytics to support dynamic, drift-aware narrative monitoring.